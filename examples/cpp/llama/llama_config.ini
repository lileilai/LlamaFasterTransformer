[ft_instance_hyperparameter]
data_type=fp16
enable_custom_all_reduce=0

tensor_para_size=2
pipeline_para_size=1

; model_name=gptneox_6B
; model_dir=/data1/lileilai/ft_0314_hf_400/

; model_name=llama_7B
; model_dir=/data1/lileilai/ft-llama-7b/


model_name=llama_13B
model_dir=/data1/lileilai/all_llama_models/ft-llama-13b/

; model_dir=/data1/lileilai/ft-llama-13b/



int8_mode=0

[request]
beam_width=1 # beam width for beam search
top_k=1 ; k value for top k sampling
top_p=0.9 ; p value for top p sampling
temperature=1.0 ; Use for sampling
repetition_penalty=1.0 ; Use for sampling
presence_penalty=0.0  ; Only one of repetition_penalty and presence_penalty are allowed.
len_penalty=0.0
beam_search_diversity_rate=0.0
request_batch_size=1 # determine by the request
request_output_len=256 # determine by the request


[llama_7B]
head_num=32
size_per_head=128
vocab_size=32000
decoder_layers=32
rotary_embedding=128  # 在llama模型中，rotary_embedding_dim等于head_dim
start_id=0
end_id=1
inter_size=11008
use_gptj_residual=0  # 对于llama模型，这里采用的不是gptj_residual

; [llama_13B]
; head_num=40
; size_per_head=128
; inter_size=13824
; decoder_layers=40
; rotary_embedding=128
; vocab_size=32000
; start_id=0
; end_id=1
; use_gptj_residual=0

[llama_13B]
head_num=40
size_per_head=128
vocab_size=32000
decoder_layers=40
rotary_embedding=128
start_id=1
end_id=2
inter_size=13824
use_gptj_residual=0



